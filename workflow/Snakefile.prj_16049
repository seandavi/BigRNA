import csv
from collections import defaultdict
srx = defaultdict(list)
with open('SraRunTable-prj_16049.tsv') as f:
    reader = csv.DictReader(f,delimiter="\t")
    for row in reader:
        if(row['Assay_Type']!="RNA-Seq"):
            continue
        srx[row['Experiment']].append(row)

# taxon_map = { "9606" : "human",
#               "10090" : "mouse"}

# def to_species(taxon_id):
#     return(taxon_map[taxon_id])

def fastq_name(species, version, ended, sample, read_no):
    return("{species}/{version}/{ended}/{sample}/{sample}_{read_no}.fastq.gz".format(
        species = species,
        version = version,
        sample = sample,
        ended=ended,
        read_no=read_no))


def pe_read1(wc):
    d = srx[wc['experiment']]
    d1 = filter(lambda val: val['LibraryLayout']=='PAIRED', d)
    fastqs = [fastq_name(species = wc.species,
                         version = wc.version,
                         ended='pe',
                         sample = val['Run'],
                         read_no = '1') for val in d1]
    return(sorted(fastqs))

def pe_read2(wc):
    d = srx[wc['experiment']]
    d1 = filter(lambda val: val['LibraryLayout']=='PAIRED', d)
    fastqs = [fastq_name(species = wc.species,
                         version = wc.version,
                         ended='pe',
                         sample = val['Run'],
                         read_no='2') for val in d1]
    return(sorted(fastqs))

def se_read(wc):
    d = srx[wc['experiment']]
    d1 = filter(lambda val: val['LibraryLayout']=='SINGLE', d)
    fastqs = [fastq_name(species = wc.species,
                         version = wc.version,
                         ended='se',
                         sample = val['Run'],
                         read_no='1') for val in d1]
    return(sorted(fastqs))

outfiles = expand("results/{species}/{version}/{experiment}/quant.sf.bz2",
           experiment = sorted(list(srx.keys())),
           version="27",
           species = "human")

rule final:
    input: outfiles

rule gencode_fasta:
    output: "reference/{species}/gencode_v{version}.transcripts.fa.gz"
    params: mem="1g"
    shell: "curl ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_{wildcards.species}/release_{wildcards.version}/gencode.v{wildcards.version}.transcripts.fa.gz > {output}"

rule gencode_gtf:
    output: "reference/{species}/gencode_v{version}.annotation.gtf"
    params: mem="1g"
    shell: "curl ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_{wildcards.species}/release_{wildcards.version}/gencode.v{wildcards.version}.annotation.gtf.gz | gunzip > {output}"


    
rule salmon_index:
    input: rules.gencode_fasta.output,
    output: "reference/{species}/gencode_v{version}/sa.bin"
    params:
        index_dir = "reference/{species}/gencode_v{version}",
        mem = "8g"
    shell: """
module load salmon/0.8.2
salmon index \
    --gencode \
    --index {params.index_dir} \
    --transcripts {input}"""




#######################################
#
# FASTQ DUMP
#
# Separate SE and PE by directory
#
#######################################
rule fastqdump_pe:
    output:
        fastq1 = temp("{species}/{version}/pe/{sample}/{sample}_1.fastq.gz"),
        fastq2 = temp("{species}/{version}/pe/{sample}/{sample}_2.fastq.gz")
    threads: 2
    resources: sra=1
    params:
        mem = "4g",
        outdir = "{species}/{version}/pe/{sample}",
        unpack_dir = "/data/sdavis2/prj_16049",
        first = lambda wildcards: wildcards.sample[0:3],
        second = lambda wildcards: wildcards.sample[0:6]
    shell: """
module load sratoolkit
export WORKDIR=`pwd`
cd {params.unpack_dir}
/data/sdavis2/projects/big_rna/prefetch_SRR.sh {wildcards.sample} {params.unpack_dir}
fastq-dump -O $WORKDIR/{params.outdir} --gzip --split-files {wildcards.sample}
rm -f sra/{wildcards.sample}.sra
rm -f sra/{wildcards.sample}.sra.lock
rm -f sra/{wildcards.sample}.sra.vdbcache
"""

rule fastqdump_se:
    output:
        fastq1 = temp("{species}/{version}/se/{sample}/{sample}_1.fastq.gz")
    threads: 2
    resources: sra=1
    params:
        mem = "4g",
        outdir = "{species}/{version}/se/{sample}",
        unpack_dir = "/data/sdavis2/prj_16049",
        first = lambda wildcards: wildcards.sample[0:3],
        second = lambda wildcards: wildcards.sample[0:6]
    shell: """
module load sratoolkit
export WORKDIR=`pwd`
cd {params.unpack_dir}
/data/sdavis2/projects/big_rna/prefetch_SRR.sh {wildcards.sample} {params.unpack_dir}
fastq-dump -O $WORKDIR/{params.outdir} --gzip --split-files {wildcards.sample}
rm -f sra/{wildcards.sample}.sra
rm -f sra/{wildcards.sample}.sra.lock
rm -f sra/{wildcards.sample}.sra.vdbcache
"""


#######################################
#
# SALMON QUANTIFY
#
# Quantify reads at the level of an
# "experiment", so combining all
# runs, including PE and SE
#
#######################################
rule salmon_quant_sra:
    input:
        pe_read1 = pe_read1,
        pe_read2 = pe_read2,
        se_read = se_read,
        index = rules.salmon_index.output,
        gtf   = rules.gencode_gtf.output
    output:
        "results/{species}/{version}/{experiment}/quant.sf.bz2"
    priority: 50
    params:
        outdir = "results/{species}/{version}/{experiment}",
        index_prefix = "reference/{species}/gencode_v{version}",
        mem = "16g",
        bootstraps = "25"
    threads: 32
    run:
        cmd = """
module load salmon/0.8.2
salmon quant --dumpEq \
    --threads {threads} \
    --numBootstraps {params.bootstraps} \
    --gcBias \
    --seqBias \
    --index {params.index_prefix} \
    --libType A \
    --output {params.outdir} \
    -g {input.gtf} """
        if(len(input.pe_read1)>0):
            cmd += " -1 {input.pe_read1} -2 {input.pe_read2} "
        if(len(input.se_read)>0):
            cmd += " -r {input.se_read}"
        cmd += """
bzip2 {params.outdir}/quant.sf
bzip2 {params.outdir}/quant.genes.sf
"""
        shell(cmd)
